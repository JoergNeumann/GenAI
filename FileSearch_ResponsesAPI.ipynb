{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvbyALyB402tCYFq5dc57E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoergNeumann/GenAI/blob/main/FileSearch_ResponsesAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#File Search\n",
        "Demonstriert die Verwendung des File Search Tools mit der Responses API."
      ],
      "metadata": {
        "id": "uebAyxJroHx-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "kXq8wDoDusgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU openai==1.52.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6a5uc3Suuaf",
        "outputId": "db8bf108-179c-4990-8f7c-afbd1383add8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/386.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m317.4/386.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3ouQx6HjoBm_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Datei hochladen"
      ],
      "metadata": {
        "id": "gvfLtXVxojWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = [\"/content/NeoGeeksAGB.pdf\"]\n",
        "file_streams = [open(path, \"rb\") for path in file_paths]"
      ],
      "metadata": {
        "id": "QY0_UkLnomiF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vector Store erstellen\n",
        "Der Vector Store wird serverseitig bei OpenAI erstellt und automatisch mit den Embeddings der zugewiesenen Dateien befüllt. Das Splitting der Dokumente und die Generierung der Embeddings wird hierbei automatisch erledigt."
      ],
      "metadata": {
        "id": "bSwk4csoowbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = client.vector_stores.create(name=\"MyAGBVectorStore\")\n",
        "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
        "    vector_store_id=vector_store.id,\n",
        "    files=file_streams\n",
        ")"
      ],
      "metadata": {
        "id": "LvQfuXfkoy_o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Datei analysieren\n",
        "Hierbei kommt das file_search Tool zum Einsatz. Als Parameter können ein oder mehrere Vector Stores angegeben werden."
      ],
      "metadata": {
        "id": "vyLnTJUJo1Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    input=\"Wie hoch ist das Zahlungsziel von NeoGeeks?\",\n",
        "    tools=[{\"type\": \"file_search\",\n",
        "            \"vector_store_ids\": [vector_store.id]}]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9tcb5ato5K2",
        "outputId": "cbae18b0-f15a-4903-82ac-15740794cc73"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Das Zahlungsziel von NeoGeeks beträgt 30 Kalendertage ab Rechnungserhalt.\n"
          ]
        }
      ]
    }
  ]
}