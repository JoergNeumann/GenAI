{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmvg7efyvxz1KXSss7Cede",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoergNeumann/GenAI/blob/main/Function%20Calling%20Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Calling Demo\n",
        "Beispiel f√ºr die Verwendung von OpenAI's Function Calling-Feature.\n",
        "\n",
        "##Setup"
      ],
      "metadata": {
        "id": "wm5sPsK58Crl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "jCstgnx5RTxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure API"
      ],
      "metadata": {
        "id": "YVHx67nNRGTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "# OpenAI API Key aus Colab Secret auslesen und OpenAI Client erstellen\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = openai.OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "g2bhegNcRZU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the function"
      ],
      "metadata": {
        "id": "11KoIQKhRkB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplified timezone data\n",
        "TIMEZONE_DATA = {\n",
        "    \"tokyo\": \"Asia/Tokyo\",\n",
        "    \"san francisco\": \"America/Los_Angeles\",\n",
        "    \"paris\": \"Europe/Paris\"\n",
        "}\n",
        "\n",
        "def get_current_time(location):\n",
        "    \"\"\"Get the current time for a given location\"\"\"\n",
        "    print(f\"get_current_time called with location: {location}\")\n",
        "    location_lower = location.lower()\n",
        "\n",
        "    for key, timezone in TIMEZONE_DATA.items():\n",
        "        if key in location_lower:\n",
        "            print(f\"Timezone found for {key}\")\n",
        "            current_time = datetime.now(ZoneInfo(timezone)).strftime(\"%I:%M %p\")\n",
        "            return json.dumps({\n",
        "                \"location\": location,\n",
        "                \"current_time\": current_time\n",
        "            })\n",
        "\n",
        "    print(f\"No timezone data found for {location_lower}\")\n",
        "    return json.dumps({\"location\": location, \"current_time\": \"unknown\"})"
      ],
      "metadata": {
        "id": "xDAZi6faRotM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the Conversation"
      ],
      "metadata": {
        "id": "edXbCSVRRtce"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-91KPn2q5OTt"
      },
      "outputs": [],
      "source": [
        "def run_conversation():\n",
        "    # Initial user message\n",
        "    messages = [{\"role\": \"user\", \"content\": \"What's the current time in San Francisco\"}] # Single function call\n",
        "    #messages = [{\"role\": \"user\", \"content\": \"What's the current time in San Francisco, Tokyo, and Paris?\"}] # Parallel function call with a single tool/function defined\n",
        "\n",
        "    # Define the function for the model\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_current_time\",\n",
        "                \"description\": \"Get the current time in a given location\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"location\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The city name, e.g. San Francisco\",\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"location\"],\n",
        "                },\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # First API call: Ask the model to use the function\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "    )\n",
        "\n",
        "    # Process the model's response\n",
        "    response_message = response.choices[0].message\n",
        "    messages.append(response_message)\n",
        "\n",
        "    print(\"Model's response:\")\n",
        "    #print(response_message)\n",
        "\n",
        "    # Handle function calls\n",
        "    if response_message.tool_calls:\n",
        "        for tool_call in response_message.tool_calls:\n",
        "            if tool_call.function.name == \"get_current_time\":\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "                print(f\"Function arguments: {function_args}\")\n",
        "                time_response = get_current_time(\n",
        "                    location=function_args.get(\"location\")\n",
        "                )\n",
        "                messages.append({\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": \"get_current_time\",\n",
        "                    \"content\": time_response,\n",
        "                })\n",
        "    else:\n",
        "        print(\"No tool calls were made by the model.\")\n",
        "\n",
        "    # Second API call: Get the final response from the model\n",
        "    final_response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    return final_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the conversation"
      ],
      "metadata": {
        "id": "tn-mZNHn7p6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_conversation())"
      ],
      "metadata": {
        "id": "uAbss0Ss70RO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}