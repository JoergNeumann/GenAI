{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoergNeumann/GenAI/blob/main/Code_Interpreter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00288aa2",
      "metadata": {
        "id": "00288aa2"
      },
      "source": [
        "# Code Interpreter\n",
        "Beispiel für die Verwendung der OpenAI Assistant API und des Code Interpreter-Features.\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "PLE_9DlFKRYS",
      "metadata": {
        "id": "PLE_9DlFKRYS",
        "outputId": "96f3a1cf-e824-4d96-9041-c64af30ca09a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.68.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: sounddevice>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from openai) (0.5.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.5.1->openai) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.5.1->openai) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5c50989",
      "metadata": {
        "id": "c5c50989"
      },
      "source": [
        "## Assistant erstellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c3d286df",
      "metadata": {
        "id": "c3d286df",
        "outputId": "8931c0d5-3ba6-49cc-8c8e-2b4c241b547f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Client.__init__() got an unexpected keyword argument 'proxies'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fe45a6db3b2c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPENAI_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morganization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morganization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_PROJECT_ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version, base_url, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query, _strict_response_validation)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     def _prepare_options(\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFinalRequestOptions\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# noqa: ARG002\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     ) -> FinalRequestOptions:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"limits\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_CONNECTION_LIMITS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"follow_redirects\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Client.__init__() got an unexpected keyword argument 'proxies'"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import os\n",
        "import time\n",
        "\n",
        "# OpenAI API Key aus Colab Secret auslesen und OpenAI Client erstellen\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "assistant = client.beta.assistants.create(\n",
        "  name=\"Technical Assistant\",\n",
        "  instructions=\"You helps people with technical issues.\",\n",
        "  tools=[{\"type\": \"code_interpreter\"}],\n",
        "  model=\"gpt-4o\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c9ffeb6",
      "metadata": {
        "id": "5c9ffeb6"
      },
      "source": [
        "## Thread erstellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ee96d7",
      "metadata": {
        "id": "85ee96d7"
      },
      "outputs": [],
      "source": [
        "thread = client.beta.threads.create()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anweisung absetzen"
      ],
      "metadata": {
        "id": "rfZw2k33hKVl"
      },
      "id": "rfZw2k33hKVl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2045959",
      "metadata": {
        "id": "b2045959"
      },
      "outputs": [],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "  thread_id=thread.id,\n",
        "  role=\"user\",\n",
        "  content=\"create a qr-code for 'www.neogeeks.de' and give it back to me.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run und Event Handler erstellen"
      ],
      "metadata": {
        "id": "BE0pTJJqKEJn"
      },
      "id": "BE0pTJJqKEJn"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import override\n",
        "from openai import AssistantEventHandler\n",
        "\n",
        "class EventHandler(AssistantEventHandler):\n",
        "  @override\n",
        "  def on_text_created(self, text) -> None:\n",
        "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
        "\n",
        "  @override\n",
        "  def on_text_delta(self, delta, snapshot):\n",
        "    print(delta.value, end=\"\", flush=True)\n",
        "\n",
        "  def on_tool_call_created(self, tool_call):\n",
        "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
        "\n",
        "  def on_tool_call_delta(self, delta, snapshot):\n",
        "    if delta.type == 'code_interpreter':\n",
        "      if delta.code_interpreter.input:\n",
        "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
        "      if delta.code_interpreter.outputs:\n",
        "        print(f\"\\n\\noutput >\", flush=True)\n",
        "        for output in delta.code_interpreter.outputs:\n",
        "          if output.type == \"logs\":\n",
        "            print(f\"\\n{output.logs}\", flush=True)\n",
        "\n",
        "\n",
        "with client.beta.threads.runs.stream(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        "  event_handler=EventHandler(),\n",
        ") as stream:\n",
        "  stream.until_done()\n"
      ],
      "metadata": {
        "id": "YQ0a5YyNKJXt"
      },
      "id": "YQ0a5YyNKJXt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mit Dateien arbeiten"
      ],
      "metadata": {
        "id": "hVJMyce36TzN"
      },
      "id": "hVJMyce36TzN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Datei hochladen\n",
        "file_path = \"/content/Umsatz.csv\"  # Pfad zur hochzuladenden Datei\n",
        "with open(file_path, \"rb\") as file:\n",
        "    uploaded_file = client.files.create(file=file, purpose=\"assistants\")\n",
        "\n",
        "# Assistenten erstellen\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Data Analyst\",\n",
        "    instructions=\"Du bist ein Assistent, der Daten analysiert und bewertet.\",\n",
        "    tools=[{\"type\": \"code_interpreter\"}],\n",
        "    tool_resources={\n",
        "      \"code_interpreter\": {\n",
        "        \"file_ids\": [uploaded_file.id]\n",
        "      }\n",
        "    },\n",
        "    model=\"gpt-4-1106-preview\",\n",
        ")\n",
        "\n",
        "# Neuen Thread erstellen\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "# Benutzeranfrage mit Datei-ID hinzufügen\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"Bitte ermittle den durchschnittlichen Umsatz in der hochgeladenen Datei.\",\n",
        ")\n",
        "\n",
        "# Ausführung starten\n",
        "run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id)\n",
        "\n",
        "# Auf Abschluss der Ausführung warten\n",
        "while run.status in [\"queued\", \"in_progress\"]:\n",
        "    time.sleep(1)\n",
        "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "\n",
        "# Ergebnisse abrufen\n",
        "if run.status == \"completed\":\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "    for msg in messages.data:\n",
        "        if msg.role == \"assistant\":\n",
        "            for content in msg.content:\n",
        "                if content.type == \"text\":\n",
        "                    print(content.text.value)\n",
        "                elif content.type == \"code\":\n",
        "                    print(\"Generierter Code:\\n\", content.code.value)\n",
        "                elif content.type == \"image_file\":\n",
        "                    print(\"Generiertes Bild:\", content.image_file.file_id)\n",
        "else:\n",
        "    print(\"Die Ausführung ist fehlgeschlagen.\")\n"
      ],
      "metadata": {
        "id": "BVqgKc-XJHSw"
      },
      "id": "BVqgKc-XJHSw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## OCR anwenden"
      ],
      "metadata": {
        "id": "KAV185c27vGT"
      },
      "id": "KAV185c27vGT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Datei hochladen\n",
        "file_path = \"/content/R240004.png\"  # Pfad zur hochzuladenden Datei\n",
        "with open(file_path, \"rb\") as file:\n",
        "    invoice_file = client.files.create(file=file, purpose=\"assistants\")\n",
        "\n",
        "# Assistenten erstellen\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Data Analyst\",\n",
        "    instructions=\"Du bist ein Assistent, der Daten analysiert und bewertet.\",\n",
        "    tools=[{\"type\": \"code_interpreter\"}],\n",
        "    tool_resources={\n",
        "      \"code_interpreter\": {\n",
        "        \"file_ids\": [invoice_file.id]\n",
        "      }\n",
        "    },\n",
        "    model=\"gpt-4-1106-preview\",\n",
        ")\n",
        "\n",
        "# Neuen Thread erstellen\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "# Benutzeranfrage mit Datei-ID hinzufügen\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"Bitte ermittle die Rechnungsnummer in der hochgeladenen Datei.\",\n",
        ")\n",
        "\n",
        "# Ausführung starten\n",
        "run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id)\n",
        "\n",
        "# Auf Abschluss der Ausführung warten\n",
        "while run.status in [\"queued\", \"in_progress\"]:\n",
        "    time.sleep(1)\n",
        "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "\n",
        "# Ergebnisse abrufen\n",
        "if run.status == \"completed\":\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "    for msg in messages.data:\n",
        "        if msg.role == \"assistant\":\n",
        "            for content in msg.content:\n",
        "                if content.type == \"text\":\n",
        "                    print(content.text.value)\n",
        "                elif content.type == \"code\":\n",
        "                    print(\"Generierter Code:\\n\", content.code.value)\n",
        "                elif content.type == \"image_file\":\n",
        "                    print(\"Generiertes Bild:\", content.image_file.file_id)\n",
        "else:\n",
        "    print(\"Die Ausführung ist fehlgeschlagen.\")"
      ],
      "metadata": {
        "id": "on0ABdvT4wQz"
      },
      "id": "on0ABdvT4wQz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}